{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51a09a42",
   "metadata": {},
   "source": [
    "##                                         Speech Emotion Recognition\n",
    "\n",
    "###  Project Idea :\n",
    "    As human beings speech is amongst the most natural way to express ourselves.\n",
    "\n",
    "    As emotions play a vital role in communication, the detection and analysis of the same is of vital importance in todayâ€™s digital world of remote communication.\n",
    "\n",
    "    Emotion detection is a challenging task, because emotions are subjective. But in this project I will try to define a SER system as a collection of methodologies that process and classify speech signals to detect emotions embedded in them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fde1e95",
   "metadata": {},
   "source": [
    "### Datasets used in this project :\n",
    "\n",
    "    -> Crowd-sourced Emotional Mutimodal Actors Dataset (Crema-D) - \"/kaggle/input/cremad/AudioWAV/\"\n",
    "    -> Ryerson Audio-Visual Database of Emotional Speech and Song (Ravdess) - \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\n",
    "    -> Surrey Audio-Visual Expressed Emotion (Savee) - \"/kaggle/input/surrey-audiovisual-expressed-emotion-savee/ALL/\"\n",
    "    -> Toronto emotional speech set (Tess) - \"/kaggle/input/toronto-emotional-speech-set-tess/tess toronto emotional speech set data/TESS Toronto emotional speech set data/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db1fcd",
   "metadata": {},
   "source": [
    "### Importing Libraries :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "609927f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to play the audio files\n",
    "from IPython.display import Audio\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "527ee515",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ravdess = os.path.abspath('Ravdess\\\\')\n",
    "Crema = os.path.abspath('Crema-D\\\\AudioWAV')\n",
    "Tess = os.path.abspath('Tess\\\\TESS Toronto emotional speech set data')\n",
    "Savee = os.path.abspath('Savee\\\\ALL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5c4f364",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-36512aed891e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# third part in each file represents the emotion associated to that file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mfile_emotion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mfile_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRavdess\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "ravdess_directory_list = os.listdir(Ravdess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "for dir in ravdess_directory_list:\n",
    "    # as their are 20 different actors in our previous directory we need to extract files for each actor.\n",
    "    actor = os.listdir(Ravdess + '\\\\' + dir)\n",
    "    for file in actor:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('-')\n",
    "        # third part in each file represents the emotion associated to that file.\n",
    "        file_emotion.append(int(part[2]))\n",
    "        file_path.append(Ravdess + dir + '/' + file)\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "\n",
    "# changing integers to actual emotions.\n",
    "Ravdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
    "Ravdess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055cbb06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
